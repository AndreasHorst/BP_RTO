{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5192f36",
   "metadata": {},
   "source": [
    "# Deconvolution with Besov Priors\n",
    "\n",
    "This notebook demonstrates the use of Besov priors for solving deconvolution problems using Bayesian inference.\n",
    "The workflow includes defining the test signal, setting up the forward model, and performing posterior sampling using RTO-MH and NUTS samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdcebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and modules\n",
    "from blurring import blurring\n",
    "from besov_prior import besov_prior\n",
    "from inverse_problem import inverse_problem\n",
    "from rto_mh import rto_mh\n",
    "import numpy as np\n",
    "import cuqi\n",
    "import time\n",
    "from scipy.special import gamma\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f3da79",
   "metadata": {},
   "source": [
    "## Step 1: Define the Test Signal\n",
    "We define a piecewise test signal with multiple intervals to simulate the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba26919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_Signal(x):\n",
    "    \"\"\"\n",
    "    Generate a piecewise smooth test signal.\n",
    "    Args:\n",
    "        x (np.ndarray): Input array of spatial points.\n",
    "    Returns:\n",
    "        Signal (np.ndarray): Piecewise smooth test signal.\n",
    "    \"\"\"\n",
    "    Signal = np.zeros(len(x))\n",
    "    interval_1 = np.logical_and(0.1 <= x, x <= 0.35)\n",
    "    interval_2 = np.logical_and(0.35 < x, x <= 0.45)\n",
    "    interval_3 = np.logical_and(0.45 < x, x <= 0.60)\n",
    "    interval_4 = np.logical_and(0.60 < x, x < 0.90)\n",
    "    # Define signal values for each interval\n",
    "    Signal[interval_1] = np.exp(-(x[interval_1]-0.35)**2*150)\n",
    "    Signal[interval_2] = 1.0\n",
    "    Signal[interval_3] = 0.8\n",
    "    Signal[interval_4] = 0.40\n",
    "    return Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a08adda",
   "metadata": {},
   "source": [
    "## Step 2: Set Up the Forward Model\n",
    "We set up the forward model using the `blurring` class, which applies a Gaussian blur to the input signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db48b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the test signal and forward model\n",
    "np.random.seed(5) # Set random seed for reproducibility\n",
    "N = 4096 # Number of spatial points\n",
    "x = np.linspace(0, 1, N, endpoint=False) # Spatial grid\n",
    "signal = Test_Signal(x) # Generate the test signal\n",
    "\n",
    "# Set up the blurring forward model\n",
    "likelihood = blurring(x,sigma_kernel=0.02)  # Gaussian kernel with sigma=0.02\n",
    "likelihood.set_data(signal,noise_level=2.0) # Add Gaussian noise with relative noise level of 2.0\n",
    "\n",
    "# Save relevant data for later use\n",
    "lam = likelihood.lam # Noise precision\n",
    "Data = likelihood.data[0::128] # Subsampled data\n",
    "m = 32 # Number of observed data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb59e3a",
   "metadata": {},
   "source": [
    "## Step 3: Bayesian Inference with different unknown dimension\n",
    "We perform Bayesian inference using the Randomize-Then-Optimize (RTO) sampler with varying wavelets and unknown dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f0b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "n_range = [32, 64, 128, 256, 512, 1024, 2048] # Different spatial resolutions\n",
    "delt = 1 # Regularization parameter\n",
    "wavelets = ['db1','db8']  # Wavelet types\n",
    "level = 0 \n",
    "nsamp = 10000 # Number of samples\n",
    "\n",
    "# Loop through wavelet types and spatial resolutions\n",
    "for wavelet in wavelets:\n",
    "    J = 5 # Initial wavelet level\n",
    "    for n in n_range:\n",
    "            x_n = np.linspace(0, 1, n, endpoint=False)\n",
    "            x0 = np.ones(len(x_n)) # Initial guess for optimization\n",
    "\n",
    "            # Set up the forward model and prior\n",
    "            likelihood = blurring(x_n,sigma_kernel=0.02, Factor= int(n/m))\n",
    "            likelihood.data = Data\n",
    "            likelihood.lam = lam\n",
    "            prior = besov_prior(J=J, delt=delt, level=level,s=1.0,p=1.5,wavelet=wavelet)\n",
    "            jac_const = likelihood.jac_const(n) @ prior.jac_const(n)\n",
    "\n",
    "            # Define the inverse problem\n",
    "            problem = inverse_problem(likelihood,prior,jac_const)\n",
    "            Nrand = m+n\n",
    "\n",
    "             # Perform RTO sampling\n",
    "            rto_sampler=rto_mh(x0,Nrand,samp=nsamp)\n",
    "            z_Map=rto_sampler.initialize_Q(problem)\n",
    "            rto_sampler.x0 = z_Map\n",
    "            xchain, acc_rate, index_accept, log_c_chain = rto_sampler.sample(problem)\n",
    "\n",
    "            # Save the results\n",
    "            np.save(\"Discrete_Invariant_Samples_\"+wavelet + \"_n=\" + str(n) + \"_s=1.0_p=1.5\" + \".npz\",xchain)\n",
    "            np.save(\"Discrete_Invariant_index_accept_\"+wavelet+\"_n=\" + str(n)+ \"_s=1.0_p=1.5\" +  \".npz\",index_accept)\n",
    "            print(acc_rate) # Print acceptance rate\n",
    "            J += 1 # Increment wavelet level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31dd2d5",
   "metadata": {},
   "source": [
    "##  Comparison between RTO and NUTS sampling\n",
    "\n",
    "We perform Bayesian inference using the Randomize-Then-Optimize (RTO) sampler and compare it with the No-U-Turn Sampler (NUTS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6841f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5) # Set random seed for reproducibility\n",
    "# Set up the test signal and forward model\n",
    "J = 9 # Wavelet level\n",
    "x=np.linspace(0, 1, 2**J, endpoint=False) # Spatial grid\n",
    "signal = Test_Signal(x) # Test signal\n",
    "\n",
    "# Setting up the forward model and generating the data\n",
    "likelihood = blurring(x,sigma_kernel=0.02)\n",
    "likelihood.set_data(signal,noise_level=2.0)\n",
    "\n",
    "# Save data for later use\n",
    "n = len(x) # Dimension of the problem\n",
    "m = len(likelihood.data) # Dimension of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a536397",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up the prior, inverse problem, and RTO sampler\n",
    "\n",
    "# Initializing prior parameters\n",
    "p = 1.5\n",
    "s = 1.0\n",
    "wavelet = 'db1'\n",
    "level = 0\n",
    "delt = 1.0\n",
    "prior = besov_prior(J = J,delt=delt, level=level,s=s,p=p,wavelet=wavelet)\n",
    "\n",
    "# Setting up the inverse problem\n",
    "jac_const = likelihood.jac_const(n) @ prior.jac_const(n)\n",
    "problem = inverse_problem(likelihood,prior,jac_const)\n",
    "\n",
    "# Setting up the RTO sampler\n",
    "Nrand = n+m\n",
    "x0 = np.ones(n)\n",
    "nsamp = 1400\n",
    "rto_sampler=rto_mh(x0,Nrand,samp=nsamp)\n",
    "\n",
    "# Initializing the RTO sampler\n",
    "zMap=rto_sampler.initialize_Q(problem)\n",
    "MAP = prior.transform(zMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a551c",
   "metadata": {},
   "source": [
    "NUTS sampling using CUQIpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105997a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1400 / 1400\n",
      "634.859375\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5) # Random seed for reproducibility\n",
    "\n",
    "# Defining the log-posterior and gradient functions of the prior\n",
    "logpdf = lambda x:-delt/((np.sqrt(gamma(1/p)/gamma(3/p)))**p)*np.linalg.norm(prior.wavelet_weigth(x),ord=p)**p\n",
    "gradient = lambda x:-p*delt/((np.sqrt(gamma(1/p)/gamma(3/p)))**p)*prior.wavelet_weight_adjoint(np.sign(prior.wavelet_weigth(x))*np.abs(prior.wavelet_weigth(x))**(p-1))\n",
    "\n",
    "# Putting the logpdf and gradient together defining the prior distribution\n",
    "xx = cuqi.distribution.UserDefinedDistribution(dim=n,logpdf_func=logpdf,gradient_func=gradient)\n",
    "\n",
    "# Setting up the forward model\n",
    "model = cuqi.model.LinearModel(likelihood.jac_const(n))\n",
    "\n",
    "# Defining the likelihood distribution\n",
    "y = cuqi.distribution.Gaussian(model(xx),likelihood.lam**2)\n",
    "\n",
    "# Setting up the joint distribution\n",
    "joint = cuqi.distribution.JointDistribution(y,xx)\n",
    "\n",
    "# Conditioning on the data to obtain the posterior distribution\n",
    "posterior = joint(y=likelihood.data)\n",
    "\n",
    "# Setting up the NUTS sampler\n",
    "sampler = cuqi.sampler.NUTS(posterior,MAP,adapt_step_size=True,opt_acc_rate=0.8)\n",
    "\n",
    "# Sampling from the posteiror distribution\n",
    "t0 = time.process_time()\n",
    "chain_NUTS = sampler.sample(1000,400)\n",
    "t1 = time.process_time()\n",
    "\n",
    "# Calculat the total time taken for sampling\n",
    "total_time_NUTS = t1-t0\n",
    "print(total_time_NUTS)\n",
    "\n",
    "# Saving results for further analysis\n",
    "np.save(\"Comparison_samples_deconvolution_NUTS.npy\",chain_NUTS.samples)\n",
    "np.save(\"Time_NUTS.npy\",total_time_NUTS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73607de",
   "metadata": {},
   "source": [
    "RTO sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbabddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7057142857142857\n",
      "757.59375\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5) # random seed for reproducibility\n",
    "\n",
    "# Initializing the start point of the RTO sampler\n",
    "rto_sampler.x0=zMap\n",
    "\n",
    "# Computing the samples\n",
    "t0 = time.process_time()\n",
    "chain_RTO, acc_rate, index_accept ,log_c_chain  = rto_sampler.sample(problem)\n",
    "t1 = time.process_time()\n",
    "\n",
    "# Calculating the total time taken for sampling\n",
    "total_time_RTO = t1-t0\n",
    "\n",
    "# Printing results\n",
    "print(acc_rate)\n",
    "print(total_time_RTO)\n",
    "chain_RTO_accept = chain_RTO[:,index_accept]\n",
    "\n",
    "# Saving results for further analysis\n",
    "np.save(\"Comparison_samples_deconvolution_RTO.npy\",chain_RTO_accept[:,0:1000])\n",
    "np.save(\"Time_RTO.npy\",total_time_RTO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f549b46",
   "metadata": {},
   "source": [
    "Effeciency comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caee12b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580.653631570516 954.1456042915211 1178.2184998559271\n",
      "0.7664445906140541 1.2594422859105174 1.5552114835370898\n",
      "240.20501208935383 677.5247660702041 1064.8625096460817\n",
      "0.3783593998109484 1.0672044751173504 1.6773202878922306\n"
     ]
    }
   ],
   "source": [
    "# Loading results RTO results and computing the effective sample size (ESS)\n",
    "chain_RTO = np.load(\"Comparison_samples_deconvolution_RTO.npy\")\n",
    "time_RTO = np.load(\"Time_RTO.npy\")\n",
    "RTO_samples = chain_RTO\n",
    "ESS_RTO = np.zeros(n)\n",
    "for i in range(n):\n",
    "    ESS_RTO[i]=az.ess(RTO_samples[i,:])\n",
    "\n",
    "# Print ESS and ESS/s    \n",
    "print(ESS_RTO.min(),np.median(ESS_RTO),ESS_RTO.max())\n",
    "print(ESS_RTO.min()/time_RTO,np.median(ESS_RTO)/time_RTO,ESS_RTO.max()/time_RTO)\n",
    "\n",
    "# Loading NUTS results and computing ESS\n",
    "chain_NUTS=np.load(\"Comparison_samples_deconvolution_NUTS.npy\")\n",
    "time_NUTS = np.load(\"Time_NUTS.npy\")\n",
    "ESS_NUTS = np.zeros(n)\n",
    "for i in range(n):\n",
    "    ESS_NUTS[i]=az.ess(chain_NUTS[i,:])\n",
    "\n",
    "# Print ESS and ESS/s    \n",
    "print(ESS_NUTS.min(),np.median(ESS_NUTS),ESS_NUTS.max())\n",
    "print(ESS_NUTS.min()/time_NUTS,np.median(ESS_NUTS)/time_NUTS,ESS_NUTS.max()/time_NUTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
